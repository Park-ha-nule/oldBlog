---
layout: post
title:  python으로 네이버 날씨 크롤링
date:   2020-09-22 21:51:00 +0000
description:  python으로 네이버 날씨 크롤링
img: python.png
tags: [More]
author: begginer_
---

# python으로 네이버 날씨 크롤링

---

> 작업 환경 : pycharm + whale

- 목차
    - python으로 크롤링하기 위해 필요한 외부 라이브러리 설치
    - 실습

### 👩🏻‍💻python으로 크롤링하기 위한 외부 라이브러리 설치(terminal)

1. BeautifulSoup : 수많은 html 태그들을 사용하기 편한 python 객체 형태로 만들어주는 것을 의미한다. ( html 코드를 python이 이해하는 객체 구조로 변환하는 Parsing을 맡고 있고, 이 라이브러리를 이용해 '의미있는' 정보를 추출 해낼수있다. )

    ```
    pip install BeautifulSoup
    ```

❗만약, BeautifulSoup을 import 했는데도 되지 않는다면?

```
pip uninstall BeautifulSoup
easy_install BeautifulSoup
```

재설치하면 된다!

2. pprint : PrettyPrinter 객체를 의미하며, 파이썬 데이터 구조를 인터프리터의 입력으로 사용할 수 있는 형태로 <예쁘게 인쇄>할 수 있는 기능을 제공한다.

(크롤링을 하기 위해 그렇게 필요한 라이브러리라고는 할 수 없다)

```
이건 따로 설치를 안해도 사용가능한 걸로 알고있다.
```

3. requests : URL에 해당하는 HTML document를 모두 가져온 다음, BeautifulSoup이라는 라이브러리를 활용하여 그것을 파싱한다.

```
pip install requests
```

### 🧐import문 작성

```python
# BeautifulSoup 라이브러리 사용(html문서를 parsing해서 python에서 쓰기위해)
from bs4 import BeautifulSoup
# 데이터가 긴 경우 보기 편하게 도와줌
from pprint import pprint
# url에 해당하는 html document를 모두 가져오기 위해
import requests
```

### ⌨️실습

 우선, 네이버 날씨를 어떻게 크롤링을 해올지를 구상해야한다. 나같은 경우는 아래의 링크에서 일주일 날씨를 크롤링 해올건데 오전/오후에 날씨와 온도, 감수량만 크롤링 해올것이다.

출처링크 : [https://n.weather.naver.com/today/09170136](https://n.weather.naver.com/today/09170136)

1. 웹페이지 요청

```python
# 크롤링하기 위해 웹 페이지를 요청하는 코드를 먼저 작성해야한다.
html = request.get('[https://n.weather.naver.com/today/09170136](https://n.weather.naver.com/today/09170136)')

# 받아온 url에 해당하는 html document를 보기 좋게 파싱 작업을 거쳐야 각 요소에 접근이 쉬워짐
soup = BeautifulSoup(html.text, 'html.parser')
```

2. 원하는 부분의 전체적인 데이터를 불러옴

<center><img src="/assets/img/crawling/01.png"></center>

  위의 링크에 들어가서 내가 가져오고 싶은 부분의 html 코드를 보자.(F12를 누르고 왼쪽 위에 마우스 부분을 누르고 해당 부분을 누르면 된다)


<center><img src="/assets/img/crawling/02.png"></center>

```python
data0 = soup.find('div', {'id' : 'weekly'})
# 확인
print('주간 예보 : ')
print(data0)
```

❓여기서 왜 주간예보 부분을 먼저 불러왔을까?

그냥, 전체를 받아왔으니 거기서 찾으면 될텐데... 라고 생각할 수 있지만 내가 주간예보 부분을 먼저 불러온 이유는 중복되는 클래스가 있기 때문이다. 전체를 다 받아오다보면 중복되는 클래스가 너무 많기 때문에 python에서 잘 불러오지 못하는 경우가 있어 주간예보를 먼저 자르고 시작하는 것이다.

3. 전체적인 데이터에서 필요한 부분만 다시 불러옴


<center><img src="/assets/img/crawling/03.png"></center>


<center><img src="/assets/img/crawling/04.png"></center>

```python
# 주간예보에서 필요한 부분 불러오기
data1 = data0.find('div', {'class' : 'scroll_area'})
# 확인
print(data1)
```

4. data1에서 날씨 부분이 속한 태그 불러오기

<i class="ico _cnLazy ico_wt1" data-ico="ico_wt1"><span class="blind">맑음</span></i>이 부분에서 '맑음'을 가져와야 함

```python
find_weather = data1.find_all('i', {'class' : 'ico _cnLazy'})
# i 태그 안에 있는 span 태그를 불러오기
for item in find_weather :
	print(item.find('span').text)
```

결과


<center><img src="/assets/img/crawling/05.png"></center>

전체 코드

```python
from bs4 import BeautifulSoup
# pprint 는 딕셔너리의 데이터가 긴 경우에 좀 더 보기 편하게 도와준다.
from pprint import pprint
import requests

# 웹페이지 요청을 하는 코드. 특정 url을 적으면 웹페이지에 대한 소스코드를 볼 수 있음
html = requests.get('https://n.weather.naver.com/today/09140104')

# 파이썬에서 보기 좋게, 파싱 작업을 거쳐야 각 요소에 접근이 쉬워짐
# 이것을 도와주는게 beautifulSoup 이다.
soup = BeautifulSoup(html.text, 'html.parser')

# 주간예보를 먼저 불러옴 (중복되는 클래스가 있어서 전체로 안하고 주간예보로 먼저 짜르고 시작함)
data0 = soup.find('div', {'id' : 'weekly'})
# print('주간 예보 : ')
# print(data0)

# 주간 예보 안에 내가 필요한 일주일 날씨 박스만 불러옴
data1 = data0.find('div', {'class':'scroll_area'})
# print(data1)

# 박스안에 날씨 부분 (맑음)이 속한 태그 불러오기
find_weather = data1.find_all('i', {'class' : 'ico _cnLazy'})
for item in find_weather:
    print(item.find('span').text)

# i 태그 안에 real weather 불러오기

# # 이후에 온도정보도 추출해보자
# find_curr_temp = data1.find('span', {'class' : 'todaytemp'}).text
# print('현재 온도 : ' + find_curr_temp + '℃')
#
# # 미세먼지와, 초미세먼지, 오존지수는 각 줄이 dd라는 공통된 태그를 갖고 있다.
# # 클래스명이 지수에 따라 계속 변화한다. find 함수는 첫 정보만을 반환하므로 findAll함수를 이용
# data2 = data1.findAll('dd')
#
# # data2 에 저장된 dd 태그 코드들 안에있는 span, num 클래스를 추출하면 총 3개의 정보를 얻을 수 있음
# find_dust = data2[0].find('span', {'class' : 'num'}).text
# find_ultra_dust = data2[1].find('span', {'class' : 'num'}).text
# find_ozon = data2[2].find('span', {'class' : 'num'}).text
# print('현재 미세먼지 : ' + find_dust)
# print('현재 초미세먼지 : ' + find_ultra_dust)
# print('현재 오존지수 : ' + find_ozon)
```
